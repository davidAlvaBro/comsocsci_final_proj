{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not import wordcloud due to an error\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import netwulf as nw\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import ast\n",
    "\n",
    "\n",
    "try:\n",
    "    from wordcloud import WordCloud\n",
    "except:\n",
    "    print('Did not import wordcloud due to an error')\n",
    "\n",
    "DATA_PATH = 'data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Word clouds"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Used to make all node ids strings\n",
    "def make_all_nodes_strings(graph):\n",
    "\n",
    "    # Check if first id is a string, in which case, don't do anyting\n",
    "    if isinstance(list(graph.nodes())[0], str):\n",
    "            return graph\n",
    "\n",
    "    # Make a mapping so each node can be renamed into what it was, but a string instead\n",
    "    node_map = {}\n",
    "    for node in graph.nodes():\n",
    "        node_map[node] = str(node)\n",
    "    str_graph = nx.relabel_nodes(graph, node_map)\n",
    "\n",
    "    return str_graph"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "shelf_graph = nx.read_graphml(DATA_PATH + 'shelves_graph_04.graphml')\n",
    "shelf_graph = make_all_nodes_strings(shelf_graph)\n",
    "\n",
    "shelf_giant = nx.Graph()\n",
    "NLP_graph = nx.read_graphml(DATA_PATH + 'NLP_graph_04.graphml')\n",
    "NLP_graph = make_all_nodes_strings(NLP_graph)\n",
    "NLP_giant = nx.Graph()\n",
    "\n",
    "shelf_louvain = np.load(DATA_PATH + 'shelves_communities_04.npy', allow_pickle = True)\n",
    "NLP_louvain = np.load(DATA_PATH + 'NLP_communities_04.npy', allow_pickle= True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "complete_book_df = pd.read_csv(DATA_PATH + \"complete_book_df.csv\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def make_attributes(df, graph):\n",
    "    book_attributes = dict()\n",
    "    for i, book in tqdm(df.iterrows(), total=df.shape[0]):\n",
    "        node = book['book_id']\n",
    "        if str(node) not in graph.nodes():\n",
    "            continue\n",
    "        book_attributes[node] = dict()\n",
    "        top_genre = book['top_genre']\n",
    "        title = book['title']\n",
    "        genres = ast.literal_eval(book['genres'])\n",
    "\n",
    "        book_attributes[node]['title'] = title\n",
    "        book_attributes[node]['genres'] = genres\n",
    "        book_attributes[node]['top_genre'] = top_genre\n",
    "    return book_attributes"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "attribute_dict = make_attributes(complete_book_df, shelf_graph)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "nx.set_node_attributes(shelf_graph, attribute_dict)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Find top three books for each community according to degree\n",
    "def get_top_3_books(graph_type, louvain_groups):\n",
    "    top_3_books = {}\n",
    "    # Store the top 3 books by degree for all communities\n",
    "    for i, community in enumerate(louvain_groups):\n",
    "        # Get the top 3 books by degree\n",
    "        sorted_dict = sorted(dict(graph_type.degree(community)).items(), key=lambda x: x[1], reverse=True)\n",
    "        names = nx.get_node_attributes(graph_type, \"title\")\n",
    "        top_3_keys = [k for k, v in sorted_dict[:3]] # Get the ID\n",
    "        top_3_names = [names[k] for k in top_3_keys] # get the name\n",
    "\n",
    "        top_3_books[i] = [(top_3_keys[j], top_3_names[j]) for j in range(len(top_3_keys))]\n",
    "        return top_3_books"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "shelf_top_3_books = get_top_3_books(shelf_giant, shelf_louvain)\n",
    "print(shelf_top_3_books)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Print the top 3 books for the 9 largest communities\n",
    "shelf_top_3_books = get_top_3_books(shelf_giant, shelf_louvain)\n",
    "NLP_top_3_books = get_top_3_books(NLP_giant, NLP_louvain)\n",
    "\n",
    "shelf_idx_9_largest = np.argsort([-len(community) for community in shelf_louvain])[:9]\n",
    "NLP_idx_9_largest = np.argsort([-len(community) for community in NLP_louvain])[:9]\n",
    "\n",
    "#For the shelf graph\n",
    "for i, community in enumerate(shelf_idx_9_largest):\n",
    "    print(f\"{i+1}. largest community {community}: \")\n",
    "    for book in shelf_top_3_books[community]:\n",
    "        print(f\"Book: {book[1]}, degree: {shelf_giant.degree(book[0])}\")\n",
    "    print()\n",
    "\n",
    "#For the shelf graph\n",
    "for i, community in enumerate(NLP_idx_9_largest):\n",
    "    print(f\"{i+1}. largest community {community}: \")\n",
    "    for book in NLP_top_3_books[community]:\n",
    "        print(f\"Book: {book[1]}, degree: {NLP_giant.degree(book[0])}\")\n",
    "    print()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "#Requires TF_IDF for each community\n",
    "\n",
    "def plot_wordcloud(TF_IDF, community, n_words=100):\n",
    "    \"\"\"Make a wordcloud from the TF-IDF scores for a given community\n",
    "    Args:\n",
    "        TF_IDF (pandas.DataFrame): Dataframe containing the TF-IDF scores for each word in the corpus\n",
    "        community (int): The community to make the wordcloud for\n",
    "        n_words (int, optional): The number of words to include in the wordcloud. Defaults to 100.\n",
    "    \"\"\"\n",
    "    word_cloud = WordCloud().generate_from_frequencies(TF_IDF[community].nlargest(n_words).to_dict()).to_image()\n",
    "    fig = plt.figure(figsize=(16, 16))\n",
    "\n",
    "    authors = [author[1] for author in top_3_books[community]]\n",
    "    plt.title(f\"Wordcloud for community {community} size {len(CSS_louvain_groups[community])}\\nTop 3 authors: {authors}\")\n",
    "    plt.imshow(word_cloud, interpolation=\"bilinear\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
