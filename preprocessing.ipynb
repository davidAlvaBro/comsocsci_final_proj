{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re \n",
    "from tqdm import tqdm\n",
    "import ast\n",
    "\n",
    "DATA_PATH = 'data/'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess the two book dataframes \n",
    "- Load dataframes ('https://sites.google.com/eng.ucsd.edu/ucsdbookgraph/home', 'https://github.com/malcolmosh/goodbooks-10k-extended/blob/master/README.md')\n",
    "- Remove faulty elements of dataframe without the descriptions \n",
    "- Remove \"additions\" to titles in the description dataframes - Example: title (series #1) -> title\n",
    "- Make a new dataframe that contains \"Book ID\" (from the dataframe without descriptions), \"Book Title\" (-||-), \"genre\" (description dataframe), \"description\" (description dataframe)\n",
    "- Store this dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataframes\n",
    "descriptions_df = pd.read_csv(DATA_PATH + \"books_descriptions.csv\")\n",
    "book_ID_df = pd.read_json(DATA_PATH + 'goodreads_book_works.json', lines=True)\n",
    "\n",
    "# Remove columns that are not needed in book_ID_df \n",
    "book_ID_df = book_ID_df.filter(items=[\"best_book_id\", \"original_title\", \"reviews_count\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount of books in descriptions_df: 10000\n",
      "Amount of books in book_ID_df: 1521962\n"
     ]
    }
   ],
   "source": [
    "# List amount of books are in each dataframe \n",
    "print(f\"Amount of books in descriptions_df: {len(descriptions_df)}\")\n",
    "print(f\"Amount of books in book_ID_df: {len(book_ID_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount of books in book_ID_df: 646906\n"
     ]
    }
   ],
   "source": [
    "# Remove faulty elements from the book_ID_df\n",
    "book_ID_df = book_ID_df[book_ID_df['original_title'] != '']\n",
    "\n",
    "print(f\"Amount of books in book_ID_df: {len(book_ID_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove faulty elements from the description dataframe\n",
    "descriptions_df = descriptions_df[descriptions_df['description'].apply(lambda x: isinstance(x, str))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9943it [00:00, 20424.75it/s]\n"
     ]
    }
   ],
   "source": [
    "# Remove \"additions\" to titles in the descriptions_df\n",
    "for i, row in tqdm(descriptions_df.iterrows()):\n",
    "    original_title = row[\"title\"]\n",
    "    new_title = re.sub(r'\\((.*)', '', original_title)\n",
    "    descriptions_df.at[i, \"title\"] = new_title.strip()\n",
    "\n",
    "# Check if it worked -> it did\n",
    "# descriptions_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lower case all titles to not have confusion in this manner \n",
    "descriptions_df['title'] = descriptions_df['title'].str.lower()\n",
    "book_ID_df['original_title'] = book_ID_df['original_title'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9943it [06:18, 26.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out of the 10000 titles 2061 are not found in the book_ID_df\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Find corresponding indexes to merge the dataframes\n",
    "titles_not_found = []\n",
    "book_df = pd.DataFrame(columns=['book_id', 'title', 'description', 'genres'])\n",
    "\n",
    "for i, row in tqdm(descriptions_df.iterrows()):\n",
    "    title = row['title']\n",
    "    # Check if the title is in book_ID_df, else append it to the titles_not_found list\n",
    "    if title in book_ID_df['original_title'].values:\n",
    "        # Get all rows that have the a matching title as the current row\n",
    "        temp_df = book_ID_df[book_ID_df['original_title'] == title]\n",
    "        \n",
    "        # Get the book id of the book  with the highest amount of reviews\n",
    "        book_id = temp_df['best_book_id'][temp_df['reviews_count'].idxmax()]\n",
    "        descriptions = row['description']\n",
    "        genres = row['genres']\n",
    "        book_df = book_df.append({'book_id': book_id, 'title': title, 'description': descriptions, 'genres': genres}, ignore_index=True)\n",
    "    else: \n",
    "        titles_not_found.append(title)\n",
    "\n",
    "# print the amount of elements that are not found\n",
    "print(f\"Out of the 10000 titles {len(titles_not_found)} are not found in the book_ID_df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Somehow the same book appears multiple times, hence we drop the duplicates\n",
    "book_df.drop_duplicates(subset=['title'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save book_df to a csv \n",
    "book_df.to_csv(DATA_PATH + 'book_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO - do this better somehow? \n",
    "# Ideas, remove all special characters (but then also \" \") \n",
    "# Convert all to tokens, then make the inner product of the tokens, normalize and take the highest value. \n",
    "\n",
    "\n",
    "# # Find corresponding indexes to merge the dataframes \n",
    "# matching_idxs = []\n",
    "\n",
    "# count = 0\n",
    "# for i, title in enumerate(descriptions_df['title']):\n",
    "#     title_found_count = 0\n",
    "#     if title in book_ID_df['original_title'].values:\n",
    "#         pass\n",
    "#         # print(f\"Found match: '{title}', at index {i}\")\n",
    "        \n",
    "#         # #Save pair of matching indexes\n",
    "#         # matching_idxs.append((i, j))\n",
    "#     else:\n",
    "        \n",
    "#         title_found = False\n",
    "#         first_match = False\n",
    "#         while True:\n",
    "#             #Check all original titles for a match\n",
    "#             for original_title in book_ID_df['original_title']:\n",
    "#                 if title == original_title[:len(title)]:\n",
    "#                     title_found = True\n",
    "#                     if not first_match:\n",
    "#                         shortest_title = original_title\n",
    "#                     else:\n",
    "#                         if len(original_title) < len(shortest_title): \n",
    "#                             shortest_title = original_title\n",
    "#             if title_found:\n",
    "#                 #print(f\"Found match: '{title}' in '{shortest_title}'\")\n",
    "#                 break\n",
    "#             title = title[:-1]\n",
    "#             if not len(title):\n",
    "#                 break\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess the shelves \n",
    "- Use \"book_id_map.csv\" to find the books we use (ids) and store \"new_ids\" (the ids we can use to find the relevant shelfs)\n",
    "- Drop all rows in \"goodreads_interactions.csv\" that have different ids than \"new_ids\". \n",
    "- Store this dataset.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataframes\n",
    "book_id_map_df = pd.read_csv(DATA_PATH + \"book_id_map.csv\")\n",
    "book_df = pd.read_csv(DATA_PATH + \"book_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-13-900ef5fc2afc>:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  book_df[\"book_id\"][i] = book_id_map[book_df[\"book_id\"][i]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out of 7690 books 15 are not in the shelf dataset and hence removed\n"
     ]
    }
   ],
   "source": [
    "# Create map from book_id to book_id_csv\n",
    "book_id_map = {book_id_map_df['book_id'][i]: book_id_map_df['book_id_csv'][i] for i in range(len(book_id_map_df))}\n",
    "\n",
    "# Change the book ID in our dataset to match the shelf dataset\n",
    "remove_list = [] # remove about 15 books that are for inexplicable reasons not in the shelf dataset\n",
    "for i in range(len(book_df)):\n",
    "    try:\n",
    "        book_df[\"book_id\"][i] = book_id_map[book_df[\"book_id\"][i]]\n",
    "    except:\n",
    "        remove_list.append(i)\n",
    "print(f\"Out of {i} books {len(remove_list)} are not in the shelf dataset and hence removed\")\n",
    "book_df.drop(remove_list, inplace=True)\n",
    "\n",
    "# Save the book_df dataframe with the index change \n",
    "book_df.to_csv(DATA_PATH + 'book_matching_ids_df.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7676\n",
      "7676\n"
     ]
    }
   ],
   "source": [
    "my_list = book_df[\"book_id\"].to_list()\n",
    "\n",
    "print(len(my_list))\n",
    "print(len(set(my_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "228648342"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the shelves dataframe (this takes some time and memory)\n",
    "shelves_df = pd.read_csv(DATA_PATH + \"goodreads_interactions.csv\")\n",
    "\n",
    "# Check how many books are on the shelves of ALL users combined \n",
    "len(shelves_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 68176467 shelves in total, and in these there are 7676 unique books.\n"
     ]
    }
   ],
   "source": [
    "# Remove books on the shelves that are not in the book_df\n",
    "shelves_df = shelves_df[shelves_df['book_id'].isin(book_df['book_id'].tolist())]\n",
    "\n",
    "# Save the new shelves_df \n",
    "shelves_df.to_csv(DATA_PATH + 'shelves_df.csv', index=False)\n",
    "\n",
    "# Check how many books are on the shelves of ALL users combined - after removal of books not in book_df\n",
    "print(f\"We have {len(shelves_df)} shelves in total, and in these there are {len(set(shelves_df['book_id'].tolist()))} unique books.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF embeddings \n",
    "- Create TF-IDF embeddings \n",
    "- Create them for genres aswell "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\david\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\david\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# imports for the text analysis\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import ast\n",
    "\n",
    "# Import the book description dataframe \n",
    "book_df = pd.read_csv(DATA_PATH + \"book_matching_ids_df.csv\") # TODO help me not make a \"Unnamed: 0\" column... I want to use the book_id as index, but then it creates this column\n",
    "\n",
    "# Logorithmic scale chosen for IDF \n",
    "BASE = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]<ipython-input-19-5d8cf50bfb36>:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  book_df['tokens'][i] = clean_tokens # str(clean_tokens)\n",
      "7676it [00:11, 675.92it/s]\n"
     ]
    }
   ],
   "source": [
    "# Create tokens from descriptions \n",
    "# Function to clean strings (from week 7)\n",
    "def clean_strings(strings):\n",
    "    \"\"\" Cleans a list of strings by removing URLs, numbers, punctuation and stop words\n",
    "    \n",
    "    Args:\n",
    "    - strings: a list of strings\n",
    "    \n",
    "    returns:\n",
    "    - cleaned_strings: a list of cleaned strings\n",
    "    \"\"\"\n",
    "    cleaned_strings = []\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "\n",
    "    for string in strings:\n",
    "        # Remove URLs\n",
    "        string = re.sub(r'http\\S+', '', string)\n",
    "\n",
    "        # Remove numbers\n",
    "        string = re.sub(r'[0-9]', '', string)\n",
    "\n",
    "        # Keep only what is not punctuation\n",
    "        string = re.sub(r'[^\\w\\s]', '', string)\n",
    "\n",
    "        # Lowercase\n",
    "        string = string.lower()\n",
    "        \n",
    "        # Remove empty strings and remove stop words and moke them\n",
    "        if len(string) and string not in stop_words and type(string) == str:\n",
    "            cleaned_strings.append(string)\n",
    "\n",
    "    return cleaned_strings\n",
    "\n",
    "# book_df.drop(axis=1, columns=['tokens'], inplace=True)\n",
    "\n",
    "# If the dataframe has not yet gotten the tokens, do it here and save it\n",
    "if not 'tokens' in book_df.columns: \n",
    "    book_df['tokens'] = None\n",
    "    for i, row in tqdm(book_df.iterrows()):\n",
    "        description = row['description']\n",
    "        # If the description is not a string, it is probably a NaN, so we set it to None\n",
    "        if type(description) == str:\n",
    "            tokens = nltk.word_tokenize(description)\n",
    "            clean_tokens = clean_strings(tokens)\n",
    "            book_df['tokens'][i] = clean_tokens # str(clean_tokens)\n",
    "\n",
    "    book_df.to_csv(DATA_PATH + 'book_matching_ids_df.csv', index=False)\n",
    "else:\n",
    "    book_df['tokens'] = book_df['tokens'].apply(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the tf scores for each community (from the previous weeks)\n",
    "def TF_from_corpus(corpus):\n",
    "    \"\"\" Calculates the TF scores for each word in the corpus\n",
    "\n",
    "    Args:\n",
    "        corpus (list): list of lists of words/strings\n",
    "\n",
    "    Returns:\n",
    "        TF_df (pandas.DataFrame): Dataframe containing the TF scores for each word in the corpus\n",
    "    \"\"\"\n",
    "    # Create empty dictionary to keep track of word counts\n",
    "    word_counts = {}\n",
    "    n_communities = len(corpus) \n",
    "    \n",
    "    # Iterate through all communities\n",
    "    for i, document in tqdm(enumerate(corpus)):\n",
    "        # Iterate through each word in the current sublist\n",
    "        for word in document:\n",
    "            # If the current word is not in the dictionary, add it with a list of zeros\n",
    "            if word not in word_counts:\n",
    "                word_counts[word] = [0] * n_communities\n",
    "            \n",
    "            # Increment count for the current word and list index\n",
    "            word_counts[word][i] += 1\n",
    "    \n",
    "    # Create pandas dataframe from the word_counts dictionary\n",
    "    TF_df = pd.DataFrame.from_dict(word_counts).transpose()\n",
    "    \n",
    "    return TF_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that takes in a TF and an IDF and computes the TF_IDF dataframe (from the previous weeks)\n",
    "def make_TF_IDF(TF_df, IDF_dict):\n",
    "    \"\"\"Multiply the TF and IDF scores to get the TF-IDF scores\n",
    "\n",
    "    Args:\n",
    "        TF_df (pandas.DataFrame): Dataframe containing the TF scores for each word in the corpus\n",
    "        IDF_dict (dict): Dictionary containing the IDF scores for each word in the corpus\n",
    "\n",
    "    Returns:\n",
    "        TF_IDF (pandas.DataFrame): Dataframe containing the TF-IDF scores for each word in the corpus\n",
    "    \"\"\"\n",
    "    # Create the TF-IDF dataframe\n",
    "    TF_IDF = pd.DataFrame(index=TF_df.index, columns=TF_df.columns)\n",
    "\n",
    "    # iterate over the index of the DataFrame\n",
    "    for word in tqdm(TF_df.index):\n",
    "        # multiply the values by the IDF_dict value\n",
    "        TF_IDF.loc[word] = TF_df.loc[word] * IDF_dict[word]\n",
    "        \n",
    "        \n",
    "    return TF_IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7676it [00:03, 2441.24it/s]\n"
     ]
    }
   ],
   "source": [
    "# Load the TF dataframe for the corpus if possible, else create it\n",
    "try:\n",
    "    TF_book_df = pd.read_csv(DATA_PATH + \"TF_book_df.csv\", index_col=0)\n",
    "except:\n",
    "    # Create it\n",
    "    TF_book_df = TF_from_corpus(book_df['tokens'])\n",
    "\n",
    "    # Rename the columns to the book_ids \n",
    "    TF_book_df.columns = book_df['book_id'].tolist()\n",
    "\n",
    "    # Save the TF dataframe \n",
    "    TF_book_df.to_csv(DATA_PATH + \"TF_book_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the total token count \"T_all_books\" and the IDF score for each book \"IDF_book_dict\" \n",
    "try:\n",
    "    IDF_dict = np.load(DATA_PATH + 'IDF_dict.npy', allow_pickle=True).item()\n",
    "except:\n",
    "    T_all_books = TF_book_df.apply(lambda row: (row != 0).sum(), axis=1)\n",
    "    # The log BASE is chosen when loading the libraries \n",
    "    IDF_dict = {word: np.emath.logn(BASE, len(TF_book_df.columns)/ T_all_books[word]) for word in TF_book_df.index}\n",
    "\n",
    "    np.save(DATA_PATH + 'IDF_dict.npy', IDF_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 62786/62786 [00:38<00:00, 1639.61it/s]\n"
     ]
    }
   ],
   "source": [
    "# Create the TF-IDF scores for each book \"TF_IDF_book_df\" if it has not already been made \n",
    "try:\n",
    "    TF_IDF_book_df = pd.read_csv(DATA_PATH + \"TF_IDF_book_df.csv\", index_col=0)\n",
    "except:\n",
    "    # Create the dataframe \n",
    "    TF_IDF_book_df = make_TF_IDF(TF_book_df, IDF_dict)\n",
    "\n",
    "    # Save the dataframe \n",
    "    TF_IDF_book_df.to_csv(DATA_PATH + \"TF_IDF_book_df.csv\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Genre TF and TF_IDF scores\n",
    "- Do this by having all books with a genre define the \"document\" for that genre \n",
    "- Then compute the \"TF_genre_df\" dataframe, by summing all books from \"TF_book_df\" from that genre\n",
    "- Here we make the decision that the IDF is the same as for the books. \n",
    "    - (Alternatively one could have weighed each book and made a new IDF score, however, this weighs a book with twice as many genres twice as large, hence we use the other option)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the set of genres\n",
    "genres = set() \n",
    "for i in book_df[\"genres\"].to_list():\n",
    "    genres = genres.union(set(ast.literal_eval(i)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7676it [00:12, 620.36it/s]\n"
     ]
    }
   ],
   "source": [
    "# Try to load the TF_genres_df, else create it\n",
    "try:\n",
    "    # Load the TF_genres_df\n",
    "    TF_genres_df = pd.read_csv(DATA_PATH + \"TF_genres_df.csv\", index_col=0)\n",
    "except: \n",
    "    # For each genre, sum all TF scores for books in that genre\n",
    "    TF_genres_df = pd.DataFrame(index=TF_book_df.index, columns=genres)\n",
    "\n",
    "    TF_genres_df = TF_genres_df.fillna(0)\n",
    "\n",
    "    # Go through all books and add the TF scores to the genres of the book\n",
    "    for i, row in tqdm(book_df.iterrows()):\n",
    "        for genre in ast.literal_eval(row['genres']):\n",
    "            TF_genres_df[genre] = TF_genres_df[genre] + TF_book_df[row['book_id']]\n",
    "            \n",
    "    # Save the genres_TF_df\n",
    "    TF_genres_df.to_csv(DATA_PATH + \"TF_genres_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 62786/62786 [00:11<00:00, 5576.23it/s]\n"
     ]
    }
   ],
   "source": [
    "# Try to load the TF_IDF_genres_df, else create it\n",
    "try:\n",
    "    # Load the TF_IDF_genres_df\n",
    "    TF_IDF_genres_df = pd.read_csv(DATA_PATH + \"TF_IDF_genres_df.csv\", index_col=0)\n",
    "except:\n",
    "    # Create the dataframe \n",
    "    TF_IDF_genres_df = make_TF_IDF(TF_genres_df, IDF_dict)\n",
    "\n",
    "    # Save the dataframe \n",
    "    TF_IDF_genres_df.to_csv(DATA_PATH + \"TF_IDF_genres_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete\n",
    "for i in list(TF_genres_df.index):\n",
    "    if type(i) != str:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Delete\n",
    "def find_diff_indexes(list1, list2):\n",
    "    diff_indexes = []\n",
    "    for i in range(len(list1)):\n",
    "        if list1[i] != list2[i]:\n",
    "            diff_indexes.append(i)\n",
    "    return diff_indexes\n",
    "\n",
    "find_diff_indexes(list(TF_genres_df.index), list(TF_book_df.index))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>art</th>\n",
       "      <th>comics</th>\n",
       "      <th>fantasy</th>\n",
       "      <th>poetry</th>\n",
       "      <th>memoir</th>\n",
       "      <th>horror</th>\n",
       "      <th>thriller</th>\n",
       "      <th>chick-lit</th>\n",
       "      <th>fiction</th>\n",
       "      <th>paranormal</th>\n",
       "      <th>...</th>\n",
       "      <th>psychology</th>\n",
       "      <th>manga</th>\n",
       "      <th>books</th>\n",
       "      <th>classics</th>\n",
       "      <th>biography</th>\n",
       "      <th>historical-fiction</th>\n",
       "      <th>history</th>\n",
       "      <th>cookbooks</th>\n",
       "      <th>humor-and-comedy</th>\n",
       "      <th>philosophy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>winning</th>\n",
       "      <td>7.048158</td>\n",
       "      <td>0.0</td>\n",
       "      <td>169.155792</td>\n",
       "      <td>28.192632</td>\n",
       "      <td>35.24079</td>\n",
       "      <td>14.096316</td>\n",
       "      <td>35.24079</td>\n",
       "      <td>42.288948</td>\n",
       "      <td>317.16711</td>\n",
       "      <td>49.337106</td>\n",
       "      <td>...</td>\n",
       "      <td>21.144474</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.096316</td>\n",
       "      <td>105.72237</td>\n",
       "      <td>91.626054</td>\n",
       "      <td>91.626054</td>\n",
       "      <td>56.385264</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.144474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>means</th>\n",
       "      <td>9.412933</td>\n",
       "      <td>23.532333</td>\n",
       "      <td>635.372998</td>\n",
       "      <td>14.1194</td>\n",
       "      <td>70.597</td>\n",
       "      <td>98.8358</td>\n",
       "      <td>230.616866</td>\n",
       "      <td>305.920332</td>\n",
       "      <td>1298.984796</td>\n",
       "      <td>357.691466</td>\n",
       "      <td>...</td>\n",
       "      <td>56.4776</td>\n",
       "      <td>14.1194</td>\n",
       "      <td>127.0746</td>\n",
       "      <td>103.542266</td>\n",
       "      <td>84.7164</td>\n",
       "      <td>202.378066</td>\n",
       "      <td>89.422866</td>\n",
       "      <td>9.412933</td>\n",
       "      <td>0.0</td>\n",
       "      <td>47.064667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fame</th>\n",
       "      <td>26.709281</td>\n",
       "      <td>6.67732</td>\n",
       "      <td>93.482484</td>\n",
       "      <td>13.354641</td>\n",
       "      <td>93.482484</td>\n",
       "      <td>26.709281</td>\n",
       "      <td>93.482484</td>\n",
       "      <td>106.837125</td>\n",
       "      <td>387.284578</td>\n",
       "      <td>13.354641</td>\n",
       "      <td>...</td>\n",
       "      <td>20.031961</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.095883</td>\n",
       "      <td>86.805164</td>\n",
       "      <td>120.191766</td>\n",
       "      <td>100.159805</td>\n",
       "      <td>60.095883</td>\n",
       "      <td>6.67732</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.67732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fortunelosing</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.906139</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.906139</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>certain</th>\n",
       "      <td>11.278705</td>\n",
       "      <td>11.278705</td>\n",
       "      <td>360.918557</td>\n",
       "      <td>16.918057</td>\n",
       "      <td>33.836115</td>\n",
       "      <td>56.393525</td>\n",
       "      <td>191.737983</td>\n",
       "      <td>152.262516</td>\n",
       "      <td>772.591286</td>\n",
       "      <td>129.705106</td>\n",
       "      <td>...</td>\n",
       "      <td>28.196762</td>\n",
       "      <td>0.0</td>\n",
       "      <td>73.311582</td>\n",
       "      <td>78.950934</td>\n",
       "      <td>39.475467</td>\n",
       "      <td>163.541221</td>\n",
       "      <td>50.754172</td>\n",
       "      <td>5.639352</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39.475467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>indistinguishably</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.906139</td>\n",
       "      <td>12.906139</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>undifferentially</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.906139</td>\n",
       "      <td>12.906139</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>manatarms</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.906139</td>\n",
       "      <td>12.906139</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>historywith</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.906139</td>\n",
       "      <td>12.906139</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>endpaper</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.906139</td>\n",
       "      <td>12.906139</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>62786 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         art     comics     fantasy     poetry     memoir  \\\n",
       "winning             7.048158        0.0  169.155792  28.192632   35.24079   \n",
       "means               9.412933  23.532333  635.372998    14.1194     70.597   \n",
       "fame               26.709281    6.67732   93.482484  13.354641  93.482484   \n",
       "fortunelosing            0.0        0.0   12.906139        0.0        0.0   \n",
       "certain            11.278705  11.278705  360.918557  16.918057  33.836115   \n",
       "...                      ...        ...         ...        ...        ...   \n",
       "indistinguishably        0.0        0.0         0.0        0.0        0.0   \n",
       "undifferentially         0.0        0.0         0.0        0.0        0.0   \n",
       "manatarms                0.0        0.0         0.0        0.0        0.0   \n",
       "historywith              0.0        0.0         0.0        0.0        0.0   \n",
       "endpaper                 0.0        0.0         0.0        0.0        0.0   \n",
       "\n",
       "                      horror    thriller   chick-lit      fiction  paranormal  \\\n",
       "winning            14.096316    35.24079   42.288948    317.16711   49.337106   \n",
       "means                98.8358  230.616866  305.920332  1298.984796  357.691466   \n",
       "fame               26.709281   93.482484  106.837125   387.284578   13.354641   \n",
       "fortunelosing            0.0         0.0         0.0    12.906139         0.0   \n",
       "certain            56.393525  191.737983  152.262516   772.591286  129.705106   \n",
       "...                      ...         ...         ...          ...         ...   \n",
       "indistinguishably        0.0         0.0         0.0          0.0         0.0   \n",
       "undifferentially         0.0         0.0         0.0          0.0         0.0   \n",
       "manatarms                0.0         0.0         0.0          0.0         0.0   \n",
       "historywith              0.0         0.0         0.0          0.0         0.0   \n",
       "endpaper                 0.0         0.0         0.0          0.0         0.0   \n",
       "\n",
       "                   ... psychology    manga      books    classics   biography  \\\n",
       "winning            ...  21.144474      0.0  14.096316   105.72237   91.626054   \n",
       "means              ...    56.4776  14.1194   127.0746  103.542266     84.7164   \n",
       "fame               ...  20.031961      0.0  60.095883   86.805164  120.191766   \n",
       "fortunelosing      ...        0.0      0.0        0.0         0.0         0.0   \n",
       "certain            ...  28.196762      0.0  73.311582   78.950934   39.475467   \n",
       "...                ...        ...      ...        ...         ...         ...   \n",
       "indistinguishably  ...        0.0      0.0        0.0         0.0         0.0   \n",
       "undifferentially   ...        0.0      0.0        0.0         0.0         0.0   \n",
       "manatarms          ...        0.0      0.0        0.0         0.0         0.0   \n",
       "historywith        ...        0.0      0.0        0.0         0.0         0.0   \n",
       "endpaper           ...        0.0      0.0        0.0         0.0         0.0   \n",
       "\n",
       "                  historical-fiction    history cookbooks humor-and-comedy  \\\n",
       "winning                    91.626054  56.385264       0.0              0.0   \n",
       "means                     202.378066  89.422866  9.412933              0.0   \n",
       "fame                      100.159805  60.095883   6.67732              0.0   \n",
       "fortunelosing                    0.0        0.0       0.0              0.0   \n",
       "certain                   163.541221  50.754172  5.639352              0.0   \n",
       "...                              ...        ...       ...              ...   \n",
       "indistinguishably          12.906139  12.906139       0.0              0.0   \n",
       "undifferentially           12.906139  12.906139       0.0              0.0   \n",
       "manatarms                  12.906139  12.906139       0.0              0.0   \n",
       "historywith                12.906139  12.906139       0.0              0.0   \n",
       "endpaper                   12.906139  12.906139       0.0              0.0   \n",
       "\n",
       "                  philosophy  \n",
       "winning            21.144474  \n",
       "means              47.064667  \n",
       "fame                 6.67732  \n",
       "fortunelosing            0.0  \n",
       "certain            39.475467  \n",
       "...                      ...  \n",
       "indistinguishably        0.0  \n",
       "undifferentially         0.0  \n",
       "manatarms                0.0  \n",
       "historywith              0.0  \n",
       "endpaper                 0.0  \n",
       "\n",
       "[62786 rows x 39 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Delete\n",
    "TF_IDF_genres_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a genre for each book\n",
    "- make the inner product which each book and the genre vector (both normed)\n",
    "- let the largest inner product that the book contains be the genre of the book "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inner_product 0.10087184173215952 young-adult\n",
      "inner_product 0.09227150818438483 fiction\n",
      "inner_product 0.09639648006828362 fantasy\n",
      "inner_product 0.10932637605734288 science-fiction\n",
      "inner_product 0.09280483506292282 romance\n",
      "('science-fiction', 0.10932637605734288)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Inner product function \n",
    "def inner_product(v1, v2):\n",
    "    \"\"\"Calculates the normed inner product of two vectors\n",
    "\n",
    "    Args:\n",
    "        v1 (list): list of numbers\n",
    "        v2 (list): list of numbers\n",
    "\n",
    "    Returns:\n",
    "        inner_product (float): inner product of the two vectors (divided by the product of their norms)\n",
    "    \"\"\"\n",
    "    \n",
    "    return np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))\n",
    "\n",
    "# Generate genre by taking inner products between each book and each genre of that book, and choosing the maximal\n",
    "def get_genres(book_df, TF_IDF_genres_df, TF_IDF_book_df): \n",
    "    # Create a dictionary to store the genre for each book\n",
    "    genres = {}\n",
    "    \n",
    "    # Go through each book \n",
    "    for i, row in tqdm(book_df.iterrows()):\n",
    "        # Get the TF-IDF scores for the current book\n",
    "        book_TF_IDF = TF_IDF_book_df[row[\"book_id\"]]\n",
    "        \n",
    "        best_genre = (None, 0)\n",
    "        \n",
    "        # Go through each genre of the book\n",
    "        for genre in ast.literal_eval(row['genres']):\n",
    "            genre_TF_IDF = TF_IDF_genres_df[genre]\n",
    "            # print(f\"inner_product {inner_product(book_TF_IDF, genre_TF_IDF)} {genre}\") # Testing\n",
    "            if inner_product(book_TF_IDF, genre_TF_IDF) > best_genre[1]:\n",
    "                best_genre = (genre, inner_product(book_TF_IDF, genre_TF_IDF))\n",
    "        # print(best_genre) # Testing\n",
    "        # break # Testing\n",
    "        # Save the best genre \n",
    "        genres[row[\"book_id\"]] = best_genre[0]\n",
    "\n",
    "    return genres\n",
    "\n",
    "# Get the genres for each book\n",
    "genres = get_genres(book_df, TF_IDF_genres_df, TF_IDF_book_df)\n",
    "\n",
    "book_df[\"top_genre\"] = book_df[\"book_id\"].map(genres)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the book_df as complete_book_df\n",
    "book_df.to_csv(DATA_PATH + \"complete_book_df.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ea8238db6dc1fe8cf6fe83219457bde9bcbcde2053d40c59d2e78211d10c5fee"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
